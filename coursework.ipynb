{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c22b4d7",
   "metadata": {},
   "source": [
    "### Ньяти Каелиле БВТ2201 - Курсовая Работа"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a730b23e",
   "metadata": {},
   "source": [
    "### 1. AutoEncoder (AE) for Noise Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a382aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from torchvision.utils import make_grid\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc75108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dims=[512, 256, 128], latent_dim=64):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        encoder_layers = []\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            encoder_layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        encoder_layers.append(nn.Linear(prev_dim, latent_dim))\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        \n",
    "        # Decoder\n",
    "        decoder_layers = []\n",
    "        hidden_dims_rev = hidden_dims[::-1]\n",
    "        prev_dim = latent_dim\n",
    "        for hidden_dim in hidden_dims_rev:\n",
    "            decoder_layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        decoder_layers.append(nn.Linear(prev_dim, input_dim))\n",
    "        decoder_layers.append(nn.Sigmoid())\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e4c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AETrainer:\n",
    "    def __init__(self, model, lr=0.001):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "    \n",
    "    def add_noise(self, images, noise_factor=0.5):\n",
    "        noisy = images + noise_factor * torch.randn_like(images)\n",
    "        return torch.clamp(noisy, 0., 1.)\n",
    "    \n",
    "    def train_epoch(self, dataloader, device):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, (data, _) in enumerate(dataloader):\n",
    "            data = data.view(data.size(0), -1).to(device)\n",
    "            \n",
    "            # Add noise to create input, use clean data as target\n",
    "            noisy_data = self.add_noise(data)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            reconstructed = self.model(noisy_data)\n",
    "            loss = self.criterion(reconstructed, data)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        return total_loss / len(dataloader)\n",
    "    \n",
    "    def evaluate(self, dataloader, device):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, _ in dataloader:\n",
    "                data = data.view(data.size(0), -1).to(device)\n",
    "                noisy_data = self.add_noise(data)\n",
    "                reconstructed = self.model(noisy_data)\n",
    "                loss = self.criterion(reconstructed, data)\n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4221f506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ae():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    model = Autoencoder().to(device)\n",
    "    trainer = AETrainer(model)\n",
    "    \n",
    "    epochs = 20\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss = trainer.train_epoch(train_loader, device)\n",
    "        test_loss = trainer.evaluate(test_loader, device)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            visualize_denoising(model, test_loader, device, epoch + 1)\n",
    "    \n",
    "    return model, trainer, train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c8b3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_denoising(model, test_loader, device, epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data, _ = next(iter(test_loader))\n",
    "        data = data[:8].to(device)\n",
    "        noisy_data = data + 0.5 * torch.randn_like(data)\n",
    "        \n",
    "        noisy_flat = noisy_data.view(noisy_data.size(0), -1)\n",
    "        reconstructed = model(noisy_flat)\n",
    "        reconstructed = reconstructed.view(-1, 1, 28, 28)\n",
    "        \n",
    "        fig, axes = plt.subplots(3, 8, figsize=(12, 5))\n",
    "        for i in range(8):\n",
    "            axes[0, i].imshow(data[i].cpu().squeeze(), cmap='gray')\n",
    "            axes[0, i].set_title('Original')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            axes[1, i].imshow(noisy_data[i].cpu().squeeze(), cmap='gray')\n",
    "            axes[1, i].set_title('Noisy')\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "            axes[2, i].imshow(reconstructed[i].cpu().squeeze(), cmap='gray')\n",
    "            axes[2, i].set_title('Denoised')\n",
    "            axes[2, i].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'AE Denoising - Epoch {epoch}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'ae_denoising_epoch_{epoch}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "413cfc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.0629, Test Loss: 0.0475\n",
      "Epoch 2/20, Train Loss: 0.0435, Test Loss: 0.0353\n",
      "Epoch 3/20, Train Loss: 0.0374, Test Loss: 0.0323\n",
      "Epoch 4/20, Train Loss: 0.0353, Test Loss: 0.0303\n",
      "Epoch 5/20, Train Loss: 0.0339, Test Loss: 0.0289\n",
      "Epoch 6/20, Train Loss: 0.0329, Test Loss: 0.0279\n",
      "Epoch 7/20, Train Loss: 0.0322, Test Loss: 0.0272\n",
      "Epoch 8/20, Train Loss: 0.0316, Test Loss: 0.0267\n",
      "Epoch 9/20, Train Loss: 0.0311, Test Loss: 0.0259\n",
      "Epoch 10/20, Train Loss: 0.0306, Test Loss: 0.0253\n",
      "Epoch 11/20, Train Loss: 0.0303, Test Loss: 0.0250\n",
      "Epoch 12/20, Train Loss: 0.0300, Test Loss: 0.0248\n",
      "Epoch 13/20, Train Loss: 0.0297, Test Loss: 0.0243\n",
      "Epoch 14/20, Train Loss: 0.0294, Test Loss: 0.0241\n",
      "Epoch 15/20, Train Loss: 0.0292, Test Loss: 0.0238\n",
      "Epoch 16/20, Train Loss: 0.0290, Test Loss: 0.0237\n",
      "Epoch 17/20, Train Loss: 0.0288, Test Loss: 0.0236\n",
      "Epoch 18/20, Train Loss: 0.0286, Test Loss: 0.0233\n",
      "Epoch 19/20, Train Loss: 0.0284, Test Loss: 0.0228\n",
      "Epoch 20/20, Train Loss: 0.0284, Test Loss: 0.0228\n",
      "Autoencoder training completed!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model, trainer, train_losses, test_losses = train_ae()\n",
    "    print(\"Autoencoder training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1256d88d",
   "metadata": {},
   "source": [
    "### 2. Variational AutoEncoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c80fe39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "epochs = 50\n",
    "latent_dim = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88808701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9abe863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE Model Definition\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Latent space\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()  # Output between 0 and 1\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891352ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    # Reconstruction loss (binary cross entropy)\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    \n",
    "    # KL divergence\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return BCE + KLD, BCE, KLD\n",
    "\n",
    "# Initialize model, optimizer\n",
    "model = VAE(latent_dim=latent_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Function to add noise to images\n",
    "def add_noise(images, noise_factor=0.5):\n",
    "    \"\"\"\n",
    "    Add Gaussian noise to images\n",
    "    \"\"\"\n",
    "    noisy_images = images + noise_factor * torch.randn_like(images)\n",
    "    noisy_images = torch.clamp(noisy_images, 0., 1.)\n",
    "    return noisy_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fd482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, dataloader, optimizer, epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_bce = 0\n",
    "    train_kld = 0\n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(dataloader):\n",
    "        # Add noise to the data\n",
    "        noisy_data = add_noise(data, noise_factor=0.5)\n",
    "        noisy_data = noisy_data.to(device)\n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(noisy_data)\n",
    "        loss, bce, kld = vae_loss(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        train_bce += bce.item()\n",
    "        train_kld += kld.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(dataloader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(dataloader):.0f}%)]\\tLoss: {loss.item() / len(data):.6f}')\n",
    "    \n",
    "    avg_loss = train_loss / len(dataloader.dataset)\n",
    "    avg_bce = train_bce / len(dataloader.dataset)\n",
    "    avg_kld = train_kld / len(dataloader.dataset)\n",
    "    \n",
    "    return avg_loss, avg_bce, avg_kld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7352a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_bce = 0\n",
    "    test_kld = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _ in dataloader:\n",
    "            # Add noise to the data\n",
    "            noisy_data = add_noise(data, noise_factor=0.5)\n",
    "            noisy_data = noisy_data.to(device)\n",
    "            data = data.to(device)\n",
    "            \n",
    "            recon_batch, mu, logvar = model(noisy_data)\n",
    "            loss, bce, kld = vae_loss(recon_batch, data, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "            test_bce += bce.item()\n",
    "            test_kld += kld.item()\n",
    "    \n",
    "    avg_loss = test_loss / len(dataloader.dataset)\n",
    "    avg_bce = test_bce / len(dataloader.dataset)\n",
    "    avg_kld = test_kld / len(dataloader.dataset)\n",
    "    \n",
    "    print(f'====> Test set loss: {avg_loss:.4f}, BCE: {avg_bce:.4f}, KLD: {avg_kld:.4f}')\n",
    "    return avg_loss, avg_bce, avg_kld\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_bce, train_kld = train(model, train_loader, optimizer, epoch)\n",
    "    test_loss, test_bce, test_kld = test(model, test_loader)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Visualization function\n",
    "def visualize_results(model, dataloader, num_images=8):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get a batch of test data\n",
    "        data, _ = next(iter(dataloader))\n",
    "        \n",
    "        # Add different levels of noise\n",
    "        noise_levels = [0.3, 0.5, 0.7]\n",
    "        \n",
    "        fig, axes = plt.subplots(len(noise_levels) + 1, num_images, figsize=(15, 10))\n",
    "        \n",
    "        # Show original images\n",
    "        for i in range(num_images):\n",
    "            axes[0, i].imshow(data[i].squeeze(), cmap='gray')\n",
    "            axes[0, i].set_title('Original')\n",
    "            axes[0, i].axis('off')\n",
    "        \n",
    "        # Show noisy and denoised images for different noise levels\n",
    "        for j, noise_factor in enumerate(noise_levels):\n",
    "            noisy_data = add_noise(data, noise_factor=noise_factor)\n",
    "            noisy_data = noisy_data.to(device)\n",
    "            recon_data, _, _ = model(noisy_data)\n",
    "            recon_data = recon_data.cpu()\n",
    "            \n",
    "            for i in range(num_images):\n",
    "                # Noisy image\n",
    "                axes[j+1, i].imshow(noisy_data[i].cpu().squeeze(), cmap='gray')\n",
    "                axes[j+1, i].set_title(f'Noisy (σ={noise_factor})')\n",
    "                axes[j+1, i].axis('off')\n",
    "                \n",
    "                # Calculate MSE for this image\n",
    "                mse = F.mse_loss(recon_data[i].view(1, 28, 28), data[i]).item()\n",
    "                axes[j+1, i].text(0.5, -0.15, f'MSE: {mse:.4f}', \n",
    "                                 transform=axes[j+1, i].transAxes, \n",
    "                                 ha='center', fontsize=8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Calculate quantitative metrics\n",
    "def calculate_metrics(model, dataloader, noise_factor=0.5):\n",
    "    model.eval()\n",
    "    total_mse = 0\n",
    "    total_psnr = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, _ in dataloader:\n",
    "            noisy_data = add_noise(data, noise_factor=noise_factor)\n",
    "            noisy_data = noisy_data.to(device)\n",
    "            data = data.to(device)\n",
    "            \n",
    "            recon_data, _, _ = model(noisy_data)\n",
    "            \n",
    "            # Calculate MSE\n",
    "            mse = F.mse_loss(recon_data, data.view(-1, 784), reduction='none')\n",
    "            mse = mse.mean(dim=1).sum().item()\n",
    "            total_mse += mse\n",
    "            \n",
    "            # Calculate PSNR\n",
    "            mse_batch = F.mse_loss(recon_data, data.view(-1, 784), reduction='none')\n",
    "            mse_batch = mse_batch.mean(dim=1)\n",
    "            psnr_batch = 20 * torch.log10(1.0 / torch.sqrt(mse_batch))\n",
    "            total_psnr += psnr_batch.sum().item()\n",
    "            \n",
    "            total_samples += data.size(0)\n",
    "    \n",
    "    avg_mse = total_mse / total_samples\n",
    "    avg_psnr = total_psnr / total_samples\n",
    "    \n",
    "    print(f\"Quantitative Results (noise σ={noise_factor}):\")\n",
    "    print(f\"Average MSE: {avg_mse:.6f}\")\n",
    "    print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "    \n",
    "    return avg_mse, avg_psnr\n",
    "\n",
    "# Display results\n",
    "print(\"\\nVisualizing results...\")\n",
    "visualize_results(model, test_loader)\n",
    "\n",
    "print(\"\\nCalculating quantitative metrics...\")\n",
    "calculate_metrics(model, test_loader, noise_factor=0.5)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, epochs + 1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Function to show individual examples with different noise levels\n",
    "def show_detailed_examples(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data, _ = next(iter(dataloader))\n",
    "        \n",
    "        noise_factors = [0.2, 0.4, 0.6, 0.8]\n",
    "        \n",
    "        fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
    "        \n",
    "        for i, noise_factor in enumerate(noise_factors):\n",
    "            # Original\n",
    "            axes[i, 0].imshow(data[i].squeeze(), cmap='gray')\n",
    "            axes[i, 0].set_title('Original')\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # Noisy\n",
    "            noisy_data = add_noise(data, noise_factor=noise_factor)\n",
    "            axes[i, 1].imshow(noisy_data[i].squeeze(), cmap='gray')\n",
    "            axes[i, 1].set_title(f'Noisy Input\\n(σ={noise_factor})')\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Denoised\n",
    "            noisy_data_device = noisy_data.to(device)\n",
    "            recon_data, _, _ = model(noisy_data_device)\n",
    "            recon_img = recon_data[i].cpu().view(28, 28)\n",
    "            axes[i, 2].imshow(recon_img, cmap='gray')\n",
    "            axes[i, 2].set_title('VAE Denoised')\n",
    "            axes[i, 2].axis('off')\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mse_noisy = F.mse_loss(noisy_data[i], data[i]).item()\n",
    "            mse_denoised = F.mse_loss(recon_img, data[i].squeeze()).item()\n",
    "            \n",
    "            # Error maps\n",
    "            error_noisy = torch.abs(noisy_data[i] - data[i])\n",
    "            error_denoised = torch.abs(recon_img - data[i].squeeze())\n",
    "            \n",
    "            axes[i, 3].imshow(error_noisy.squeeze(), cmap='hot')\n",
    "            axes[i, 3].set_title(f'Noisy Error\\nMSE: {mse_noisy:.4f}')\n",
    "            axes[i, 3].axis('off')\n",
    "            \n",
    "            axes[i, 4].imshow(error_denoised, cmap='hot')\n",
    "            axes[i, 4].set_title(f'Denoised Error\\nMSE: {mse_denoised:.4f}')\n",
    "            axes[i, 4].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"\\nShowing detailed examples with error analysis...\")\n",
    "show_detailed_examples(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ea28c",
   "metadata": {},
   "source": [
    "### 3. Generative Adversarial Network (GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0629b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "learning_rate = 0.0002\n",
    "epochs = 50\n",
    "latent_dim = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b535c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Fixed noise for visualization\n",
    "fixed_noise = torch.randn(64, latent_dim, device=device)\n",
    "\n",
    "# Generator Network\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # Input: latent_dim\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb20b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Network\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # Input: 784 (28x28)\n",
    "            nn.Linear(784, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        return self.main(x)\n",
    "\n",
    "# Initialize networks\n",
    "generator = Generator(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "# Two optimizers - one for generator, one for discriminator\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Lists to track progress\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "D_real_losses = []\n",
    "D_fake_losses = []\n",
    "\n",
    "# Training function\n",
    "def train_gan(epoch):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    \n",
    "    for i, (real_imgs, _) in enumerate(train_loader):\n",
    "        batch_size = real_imgs.size(0)\n",
    "        \n",
    "        # Move real images to device\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        \n",
    "        # Create labels\n",
    "        real_labels = torch.ones(batch_size, 1, device=device)\n",
    "        fake_labels = torch.zeros(batch_size, 1, device=device)\n",
    "        \n",
    "        # ========================\n",
    "        #  Train Discriminator\n",
    "        # ========================\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        # Loss with real images\n",
    "        real_output = discriminator(real_imgs)\n",
    "        d_loss_real = criterion(real_output, real_labels)\n",
    "        \n",
    "        # Generate fake images\n",
    "        noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "        fake_imgs = generator(noise)\n",
    "        \n",
    "        # Loss with fake images\n",
    "        fake_output = discriminator(fake_imgs.detach())\n",
    "        d_loss_fake = criterion(fake_output, fake_labels)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        # ========================\n",
    "        #  Train Generator\n",
    "        # ========================\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Generate new fake images\n",
    "        noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "        fake_imgs = generator(noise)\n",
    "        \n",
    "        # Generator wants discriminator to think fake images are real\n",
    "        fake_output = discriminator(fake_imgs)\n",
    "        g_loss = criterion(fake_output, real_labels)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        # Save losses for plotting\n",
    "        if i % 50 == 0:\n",
    "            G_losses.append(g_loss.item())\n",
    "            D_losses.append(d_loss.item())\n",
    "            D_real_losses.append(d_loss_real.item())\n",
    "            D_fake_losses.append(d_loss_fake.item())\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'[{epoch}/{epochs}][{i}/{len(train_loader)}] '\n",
    "                  f'D_loss: {d_loss.item():.4f} '\n",
    "                  f'G_loss: {g_loss.item():.4f} '\n",
    "                  f'D(x): {real_output.mean().item():.4f} '\n",
    "                  f'D(G(z)): {fake_output.mean().item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33743e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate and save images\n",
    "def generate_images(epoch):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        fake_images = generator(fixed_noise).detach().cpu()\n",
    "        \n",
    "        # Denormalize from [-1, 1] to [0, 1]\n",
    "        fake_images = (fake_images + 1) / 2\n",
    "        \n",
    "        # Create grid of images\n",
    "        grid = make_grid(fake_images, nrow=8, normalize=True)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(grid.permute(1, 2, 0), cmap='gray')\n",
    "        plt.title(f'Generated Images - Epoch {epoch}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        return grid\n",
    "\n",
    "# Function to show training progress\n",
    "def plot_training_progress():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    ax1.plot(G_losses, label='Generator Loss')\n",
    "    ax1.plot(D_losses, label='Discriminator Loss')\n",
    "    ax1.set_xlabel('Iterations')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Generator and Discriminator Losses')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot discriminator components\n",
    "    ax2.plot(D_real_losses, label='D Real Loss', alpha=0.7)\n",
    "    ax2.plot(D_fake_losses, label='D Fake Loss', alpha=0.7)\n",
    "    ax2.set_xlabel('Iterations')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_title('Discriminator Real vs Fake Losses')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83247dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show real vs fake comparison\n",
    "def show_real_vs_fake():\n",
    "    # Get some real images\n",
    "    real_imgs, _ = next(iter(train_loader))\n",
    "    real_imgs = real_imgs[:32]\n",
    "    \n",
    "    # Generate fake images\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(32, latent_dim, device=device)\n",
    "        fake_imgs = generator(noise).detach().cpu()\n",
    "    \n",
    "    # Denormalize\n",
    "    real_imgs = (real_imgs + 1) / 2\n",
    "    fake_imgs = (fake_imgs + 1) / 2\n",
    "    \n",
    "    # Create grids\n",
    "    real_grid = make_grid(real_imgs, nrow=8, normalize=False)\n",
    "    fake_grid = make_grid(fake_imgs, nrow=8, normalize=False)\n",
    "    \n",
    "    # Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    ax1.imshow(real_grid.permute(1, 2, 0), cmap='gray')\n",
    "    ax1.set_title('Real MNIST Images')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(fake_grid.permute(1, 2, 0), cmap='gray')\n",
    "    ax2.set_title('Generated Images')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to show interpolation in latent space\n",
    "def show_latent_interpolation():\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        # Create two random points in latent space\n",
    "        z1 = torch.randn(1, latent_dim, device=device)\n",
    "        z2 = torch.randn(1, latent_dim, device=device)\n",
    "        \n",
    "        # Interpolate between them\n",
    "        num_steps = 10\n",
    "        interpolated = []\n",
    "        \n",
    "        for alpha in torch.linspace(0, 1, num_steps):\n",
    "            z = alpha * z1 + (1 - alpha) * z2\n",
    "            img = generator(z).detach().cpu()\n",
    "            interpolated.append(img)\n",
    "        \n",
    "        # Create grid\n",
    "        interpolated = torch.cat(interpolated, 0)\n",
    "        interpolated = (interpolated + 1) / 2  # Denormalize\n",
    "        grid = make_grid(interpolated, nrow=num_steps, normalize=False)\n",
    "        \n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 2))\n",
    "        plt.imshow(grid.permute(1, 2, 0), cmap='gray')\n",
    "        plt.title('Latent Space Interpolation')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting GAN training...\")\n",
    "print(\"Generator architecture:\")\n",
    "print(generator)\n",
    "print(\"\\nDiscriminator architecture:\")\n",
    "print(discriminator)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_gan(epoch)\n",
    "    \n",
    "    # Generate sample images every 5 epochs\n",
    "    if epoch % 5 == 0 or epoch == 1:\n",
    "        print(f\"\\nGenerating sample images at epoch {epoch}...\")\n",
    "        generate_images(epoch)\n",
    "\n",
    "# Final results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GAN TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show final generated images\n",
    "print(\"\\nFinal generated images:\")\n",
    "final_images = generate_images(epochs)\n",
    "\n",
    "# Show training progress\n",
    "print(\"\\nTraining progress:\")\n",
    "plot_training_progress()\n",
    "\n",
    "# Show real vs fake comparison\n",
    "print(\"\\nReal vs Generated images comparison:\")\n",
    "show_real_vs_fake()\n",
    "\n",
    "# Show latent space interpolation\n",
    "print(\"\\nLatent space interpolation:\")\n",
    "show_latent_interpolation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate multiple samples\n",
    "def generate_multiple_samples(num_samples=64):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_samples, latent_dim, device=device)\n",
    "        fake_images = generator(noise).detach().cpu()\n",
    "        fake_images = (fake_images + 1) / 2  # Denormalize\n",
    "        \n",
    "        grid = make_grid(fake_images, nrow=8, normalize=False)\n",
    "        \n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(grid.permute(1, 2, 0), cmap='gray')\n",
    "        plt.title('Multiple Generated Samples')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "        return fake_images\n",
    "\n",
    "# Generate multiple samples\n",
    "print(\"\\nGenerating multiple samples...\")\n",
    "generated_samples = generate_multiple_samples(64)\n",
    "\n",
    "# Save model\n",
    "torch.save(generator.state_dict(), 'gan_generator.pth')\n",
    "torch.save(discriminator.state_dict(), 'gan_discriminator.pth')\n",
    "print(\"\\nModels saved as 'gan_generator.pth' and 'gan_discriminator.pth'\")\n",
    "\n",
    "# Print final statistics\n",
    "print(f\"\\nFinal Statistics:\")\n",
    "print(f\"Total generator iterations: {len(G_losses)}\")\n",
    "print(f\"Final generator loss: {G_losses[-1]:.4f}\")\n",
    "print(f\"Final discriminator loss: {D_losses[-1]:.4f}\")\n",
    "print(f\"Training completed on: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional demonstration: Show evolution of generated images\n",
    "def show_training_evolution():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING EVOLUTION DEMONSTRATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Create a new generator and show how images improve with training\n",
    "    test_generator = Generator(latent_dim).to(device)\n",
    "    test_generator.apply(weights_init)\n",
    "    \n",
    "    # Generate with untrained generator\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(16, latent_dim, device=device)\n",
    "        untrained_imgs = test_generator(noise).detach().cpu()\n",
    "        untrained_imgs = (untrained_imgs + 1) / 2\n",
    "    \n",
    "    # Compare with trained generator\n",
    "    with torch.no_grad():\n",
    "        trained_imgs = generator(noise).detach().cpu()\n",
    "        trained_imgs = (trained_imgs + 1) / 2\n",
    "    \n",
    "    # Plot comparison\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    untrained_grid = make_grid(untrained_imgs, nrow=4, normalize=False)\n",
    "    trained_grid = make_grid(trained_imgs, nrow=4, normalize=False)\n",
    "    \n",
    "    ax1.imshow(untrained_grid.permute(1, 2, 0), cmap='gray')\n",
    "    ax1.set_title('Untrained Generator\\n(Random Output)')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2.imshow(trained_grid.permute(1, 2, 0), cmap='gray')\n",
    "    ax2.set_title('Trained Generator\\n(Realistic Digits)')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_training_evolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final demonstration\n",
    "def demonstrate_generation():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"FINAL DEMONSTRATION: GAN IMAGE GENERATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(\"Key points to present during defense:\")\n",
    "    print(\"✓ The generator takes random noise (100-dimensional vector) as input\")\n",
    "    print(\"✓ It transforms this noise into realistic 28x28 digit images\")\n",
    "    print(\"✓ The discriminator learns to distinguish real from fake images\")\n",
    "    print(\"✓ Two separate optimizers train the networks adversarially\")\n",
    "    print(\"✓ No labels are used - purely unsupervised learning\")\n",
    "    print(\"✓ The generated images show the model learned the MNIST data distribution\")\n",
    "    \n",
    "    # Generate one final impressive set\n",
    "    print(\"\\nFinal generated images demonstration:\")\n",
    "    generate_multiple_samples(25)\n",
    "\n",
    "demonstrate_generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ebc4a",
   "metadata": {},
   "source": [
    "### 4. Denoising Diffusion Probabilistic Model (DDPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e027227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Layer Implementation\n",
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_features) * 0.1)\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = x @ self.weight.t()\n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "        return output\n",
    "\n",
    "# Activation Functions\n",
    "class ReLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.maximum(x, torch.zeros_like(x))\n",
    "\n",
    "class SiLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "# Sinusoidal Position Embedding\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((torch.sin(emb), torch.cos(emb)), dim=-1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93f304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved U-Net Block with proper dimension handling\n",
    "class UNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_emb_dim, is_upsample=False):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Linear(time_emb_dim, out_channels)\n",
    "        \n",
    "        if is_upsample:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "            \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.activation = SiLU()\n",
    "        \n",
    "        self.norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.norm2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        if in_channels != out_channels:\n",
    "            self.res_conv = nn.Conv2d(in_channels, out_channels, 1)\n",
    "        else:\n",
    "            self.res_conv = nn.Identity()\n",
    "    \n",
    "    def forward(self, x, t_emb):\n",
    "        # First convolution\n",
    "        h = self.conv1(x)\n",
    "        h = self.norm1(h)\n",
    "        h = self.activation(h)\n",
    "        \n",
    "        # Add time embedding\n",
    "        t_emb = self.time_mlp(t_emb)\n",
    "        h = h + t_emb[:, :, None, None]\n",
    "        \n",
    "        # Second convolution\n",
    "        h = self.conv2(h)\n",
    "        h = self.norm2(h)\n",
    "        h = self.activation(h)\n",
    "        \n",
    "        # Residual connection\n",
    "        return h + self.res_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77219237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust DDPM Model with proper dimension handling\n",
    "class RobustDiffusionModel(nn.Module):\n",
    "    def __init__(self, image_size=28, channels=1, dim=32, time_emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.image_size = image_size\n",
    "        self.channels = channels\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalPosEmb(time_emb_dim),\n",
    "            LinearLayer(time_emb_dim, time_emb_dim),\n",
    "            SiLU(),\n",
    "            LinearLayer(time_emb_dim, time_emb_dim)\n",
    "        )\n",
    "        \n",
    "        # Initial convolution\n",
    "        self.init_conv = nn.Conv2d(channels, dim, 3, padding=1)\n",
    "        \n",
    "        # Encoder path with proper downsampling\n",
    "        self.enc1 = UNetBlock(dim, dim, time_emb_dim)\n",
    "        self.enc2 = UNetBlock(dim, dim*2, time_emb_dim)\n",
    "        self.enc3 = UNetBlock(dim*2, dim*4, time_emb_dim)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = UNetBlock(dim*4, dim*4, time_emb_dim)\n",
    "        \n",
    "        # Decoder path with proper upsampling\n",
    "        self.dec1 = UNetBlock(dim*8, dim*2, time_emb_dim, is_upsample=True)\n",
    "        self.dec2 = UNetBlock(dim*4, dim, time_emb_dim, is_upsample=True)\n",
    "        self.dec3 = UNetBlock(dim*2, dim, time_emb_dim, is_upsample=True)\n",
    "        \n",
    "        # Final output\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(dim, dim, 3, padding=1),\n",
    "            SiLU(),\n",
    "            nn.Conv2d(dim, channels, 1)\n",
    "        )\n",
    "        \n",
    "        # Pooling and upsampling\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        # Time embedding\n",
    "        t_emb = self.time_mlp(t)\n",
    "        \n",
    "        # Initial convolution\n",
    "        x0 = self.init_conv(x)\n",
    "        \n",
    "        # Encoder with proper downsampling\n",
    "        e1 = self.enc1(x0, t_emb)                    # 28x28\n",
    "        e1_pool = self.pool(e1)                      # 14x14\n",
    "        \n",
    "        e2 = self.enc2(e1_pool, t_emb)              # 14x14\n",
    "        e2_pool = self.pool(e2)                      # 7x7\n",
    "        \n",
    "        e3 = self.enc3(e2_pool, t_emb)              # 7x7\n",
    "        e3_pool = self.pool(e3)                      # 3x3\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(e3_pool, t_emb) # 3x3\n",
    "        \n",
    "        # Decoder with proper upsampling and skip connections\n",
    "        # Upsample to match e3 dimensions\n",
    "        d1 = F.interpolate(bottleneck, size=e3.shape[2:], mode='nearest')  # 7x7\n",
    "        d1 = torch.cat([d1, e3], dim=1)              # Concatenate along channels\n",
    "        d1 = self.dec1(d1, t_emb)                    # 7x7\n",
    "        \n",
    "        # Upsample to match e2 dimensions\n",
    "        d2 = F.interpolate(d1, size=e2.shape[2:], mode='nearest')  # 14x14\n",
    "        d2 = torch.cat([d2, e2], dim=1)              # Concatenate along channels\n",
    "        d2 = self.dec2(d2, t_emb)                    # 14x14\n",
    "        \n",
    "        # Upsample to match e1 dimensions\n",
    "        d3 = F.interpolate(d2, size=e1.shape[2:], mode='nearest')  # 28x28\n",
    "        d3 = torch.cat([d3, e1], dim=1)              # Concatenate along channels\n",
    "        d3 = self.dec3(d3, t_emb)                    # 28x28\n",
    "        \n",
    "        # Final output\n",
    "        return self.final_conv(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDPM Trainer\n",
    "class DDPM:\n",
    "    def __init__(self, model, timesteps=200, beta_start=1e-4, beta_end=0.02, device='cuda'):\n",
    "        self.model = model\n",
    "        self.timesteps = timesteps\n",
    "        self.device = device\n",
    "        \n",
    "        # Linear noise schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, timesteps, device=device)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "        \n",
    "        # Pre-calculate values for sampling\n",
    "        self.sqrt_alpha_bars = torch.sqrt(self.alpha_bars)\n",
    "        self.sqrt_one_minus_alpha_bars = torch.sqrt(1. - self.alpha_bars)\n",
    "    \n",
    "    def sample_timesteps(self, n):\n",
    "        return torch.randint(0, self.timesteps, (n,), device=self.device)\n",
    "    \n",
    "    def noise_images(self, x, t):\n",
    "        sqrt_alpha_bar = self.sqrt_alpha_bars[t][:, None, None, None]\n",
    "        sqrt_one_minus_alpha_bar = self.sqrt_one_minus_alpha_bars[t][:, None, None, None]\n",
    "        epsilon = torch.randn_like(x)\n",
    "        return sqrt_alpha_bar * x + sqrt_one_minus_alpha_bar * epsilon, epsilon\n",
    "    \n",
    "    def train_step(self, x, optimizer):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        t = self.sample_timesteps(x.shape[0])\n",
    "        x_noisy, noise = self.noise_images(x, t)\n",
    "        predicted_noise = self.model(x_noisy, t)\n",
    "        \n",
    "        loss = F.mse_loss(predicted_noise, noise)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, n_samples=16, img_size=28, channels=1):\n",
    "        self.model.eval()\n",
    "        x = torch.randn((n_samples, channels, img_size, img_size), device=self.device)\n",
    "        \n",
    "        for i in tqdm(reversed(range(self.timesteps)), desc='Sampling'):\n",
    "            t = torch.full((n_samples,), i, device=self.device, dtype=torch.long)\n",
    "            predicted_noise = self.model(x, t)\n",
    "            \n",
    "            alpha = self.alphas[t][:, None, None, None]\n",
    "            alpha_bar = self.alpha_bars[t][:, None, None, None]\n",
    "            beta = self.betas[t][:, None, None, None]\n",
    "            \n",
    "            if i > 0:\n",
    "                noise = torch.randn_like(x)\n",
    "            else:\n",
    "                noise = torch.zeros_like(x)\n",
    "            \n",
    "            # DDPM sampling formula\n",
    "            x = (1 / torch.sqrt(alpha)) * (\n",
    "                x - ((1 - alpha) / (torch.sqrt(1 - alpha_bar))) * predicted_noise\n",
    "            ) + torch.sqrt(beta) * noise\n",
    "        \n",
    "        self.model.train()\n",
    "        return torch.clamp(x, -1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac84090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_ddpm():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Data preparation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "    \n",
    "    # Model and trainer\n",
    "    model = RobustDiffusionModel().to(device)\n",
    "    ddpm = DDPM(model, device=device, timesteps=200)  # Reduced timesteps for faster training\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    # Training loop\n",
    "    epochs = 15\n",
    "    losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        \n",
    "        for batch_idx, (data, _) in enumerate(progress_bar):\n",
    "            data = data.to(device)\n",
    "            loss = ddpm.train_step(data, optimizer)\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            progress_bar.set_postfix({'Loss': f'{loss:.4f}'})\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        losses.append(avg_loss)\n",
    "        print(f'Epoch {epoch+1}, Average Loss: {avg_loss:.4f}')\n",
    "        \n",
    "        # Sample and save images every 3 epochs\n",
    "        if (epoch + 1) % 3 == 0:\n",
    "            samples = ddpm.sample(n_samples=16)\n",
    "            save_samples(samples, epoch + 1)\n",
    "    \n",
    "    return model, ddpm, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1228ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(samples, epoch, nrow=4):\n",
    "    samples = samples.cpu()\n",
    "    samples = (samples + 1) / 2  # Denormalize\n",
    "    samples = samples.clamp(0, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(nrow, nrow, figsize=(8, 8))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(samples):\n",
    "            ax.imshow(samples[i].squeeze(), cmap='gray')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'ddpm_samples_epoch_{epoch}.png')\n",
    "    plt.close()\n",
    "    print(f\"Saved samples for epoch {epoch}\")\n",
    "\n",
    "\n",
    "def test_model():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Testing on device: {device}\")\n",
    "    \n",
    "    model = RobustDiffusionModel().to(device)\n",
    "    \n",
    "    # Test with different batch sizes\n",
    "    batch_sizes = [1, 4, 8]\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"\\nTesting with batch size {batch_size}:\")\n",
    "        \n",
    "        # Test forward pass\n",
    "        x = torch.randn(batch_size, 1, 28, 28).to(device)\n",
    "        t = torch.randint(0, 200, (batch_size,)).to(device)\n",
    "        \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                output = model(x, t)\n",
    "            \n",
    "            print(f\"  Input shape: {x.shape}\")\n",
    "            print(f\"  Output shape: {output.shape}\")\n",
    "            print(f\"  Forward pass successful\")\n",
    "            \n",
    "            # Test that input and output have same spatial dimensions\n",
    "            assert x.shape[2:] == output.shape[2:], \"Spatial dimensions don't match!\"\n",
    "            print(f\"  Spatial dimensions match\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "            return False\n",
    "    \n",
    "    print(\"\\n All tests passed! Model architecture is correct.\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d37a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Testing model architecture...\")\n",
    "    success = test_model()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nStarting training...\")\n",
    "        model, ddpm, losses = train_ddpm()\n",
    "        \n",
    "        # Plot training loss\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(losses)\n",
    "        plt.title('DDPM Training Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MSE Loss')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('ddpm_training_loss.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # Generate final samples\n",
    "        print(\"Generating final samples...\")\n",
    "        final_samples = ddpm.sample(n_samples=64)\n",
    "        save_samples(final_samples, \"final\")\n",
    "        \n",
    "        print(\"Training completed successfully!\")\n",
    "    else:\n",
    "        print(\"Model testing failed. Please check the architecture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bde68c",
   "metadata": {},
   "source": [
    "### 5. Vector Autoregressive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc6119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAR Model for MNIST with Linear Layers\n",
    "class MNISTVARModel(nn.Module):\n",
    "    def __init__(self, input_dim, lag_order=5, hidden_dims=[512, 256, 128]):\n",
    "        super(MNISTVARModel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.lag_order = lag_order\n",
    "        \n",
    "        # Flatten the lagged sequences: lag_order * input_dim\n",
    "        self.flattened_dim = lag_order * input_dim\n",
    "        \n",
    "        # Linear layers for VAR modeling\n",
    "        layers = []\n",
    "        prev_dim = self.flattened_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        \n",
    "        # Output layer to predict all variables (pixels)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(prev_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, input_dim),\n",
    "            nn.Tanh()  # Output in range [-1, 1] for normalized images\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, lag_order, input_dim)\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Flatten the lagged sequences\n",
    "        x_flat = x.view(batch_size, -1)  # (batch_size, lag_order * input_dim)\n",
    "        \n",
    "        # Process through linear layers\n",
    "        encoded = self.encoder(x_flat)\n",
    "        \n",
    "        # Predict next time step (next MNIST image)\n",
    "        prediction = self.output_layer(encoded)  # (batch_size, input_dim)\n",
    "        \n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88e7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST VAR Trainer\n",
    "class MNISTVARTrainer:\n",
    "    def __init__(self, model, lr=0.001):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.scaler = StandardScaler()\n",
    "    \n",
    "    def create_mnist_sequences(self, data, labels, lag_order, sequence_length=1000):\n",
    "        \"\"\"Create sequential sequences from MNIST data\"\"\"\n",
    "        # Treat different MNIST samples as sequential time steps\n",
    "        sequences = []\n",
    "        targets = []\n",
    "        \n",
    "        # Use first sequence_length samples to create sequences\n",
    "        data_subset = data[:sequence_length + lag_order]\n",
    "        \n",
    "        for i in range(len(data_subset) - lag_order):\n",
    "            seq = data_subset[i:i+lag_order]  # (lag_order, input_dim)\n",
    "            target = data_subset[i+lag_order]  # (input_dim)\n",
    "            sequences.append(seq)\n",
    "            targets.append(target)\n",
    "        \n",
    "        return torch.FloatTensor(np.array(sequences)), torch.FloatTensor(np.array(targets))\n",
    "    \n",
    "    def prepare_mnist_data(self, batch_size=64, train_ratio=0.8):\n",
    "        \"\"\"Load and prepare MNIST data for VAR modeling\"\"\"\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)),  # Normalize to [-1, 1]\n",
    "            transforms.Lambda(lambda x: x.view(-1))  # Flatten images\n",
    "        ])\n",
    "        \n",
    "        # Load MNIST dataset\n",
    "        train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "        test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "        \n",
    "        # Combine train and test for more sequential data\n",
    "        all_data = torch.cat([train_dataset.data, test_dataset.data])\n",
    "        all_labels = torch.cat([train_dataset.targets, test_dataset.targets])\n",
    "        \n",
    "        # Convert to numpy and normalize\n",
    "        all_data = all_data.float() / 255.0  # Normalize to [0, 1]\n",
    "        all_data = all_data.numpy()\n",
    "        all_labels = all_labels.numpy()\n",
    "        \n",
    "        # Flatten images\n",
    "        all_data_flat = all_data.reshape(len(all_data), -1)\n",
    "        \n",
    "        # Create sequences\n",
    "        sequences, targets = self.create_mnist_sequences(all_data_flat, all_labels, self.model.lag_order)\n",
    "        \n",
    "        # Split into train and test\n",
    "        split_idx = int(len(sequences) * train_ratio)\n",
    "        \n",
    "        X_train, X_test = sequences[:split_idx], sequences[split_idx:]\n",
    "        y_train, y_test = targets[:split_idx], targets[split_idx:]\n",
    "        \n",
    "        print(f\"Created {len(X_train)} training sequences and {len(X_test)} test sequences\")\n",
    "        print(f\"Input shape: {X_train.shape}, Target shape: {y_train.shape}\")\n",
    "        \n",
    "        return (X_train, y_train, X_test, y_test), all_data, all_labels\n",
    "    \n",
    "    def train(self, epochs=100, patience=10):\n",
    "        \"\"\"Train the VAR model with early stopping\"\"\"\n",
    "        # Prepare data\n",
    "        (X_train, y_train, X_test, y_test), original_data, labels = self.prepare_mnist_data()\n",
    "        \n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        best_test_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            self.model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            train_predictions = self.model(X_train)\n",
    "            train_loss = self.criterion(train_predictions, y_train)\n",
    "            train_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Validation\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_predictions = self.model(X_test)\n",
    "                test_loss = self.criterion(test_predictions, y_test)\n",
    "            \n",
    "            train_losses.append(train_loss.item())\n",
    "            test_losses.append(test_loss.item())\n",
    "            \n",
    "            # Early stopping\n",
    "            if test_loss < best_test_loss:\n",
    "                best_test_loss = test_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(self.model.state_dict(), 'best_mnist_var_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch {epoch:3d}/{epochs}: Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}')\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(f'Early stopping at epoch {epoch}')\n",
    "                break\n",
    "        \n",
    "        # Load best model\n",
    "        self.model.load_state_dict(torch.load('best_mnist_var_model.pth'))\n",
    "        \n",
    "        return train_losses, test_losses, (X_train, y_train, X_test, y_test), original_data, labels\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def predict_sequence(self, initial_sequence, steps=10):\n",
    "        \"\"\"Generate a sequence of predictions\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        predictions = []\n",
    "        current_sequence = initial_sequence.clone()\n",
    "        \n",
    "        for _ in range(steps):\n",
    "            # Get prediction for next time step\n",
    "            pred = self.model(current_sequence.unsqueeze(0)).squeeze(0)\n",
    "            predictions.append(pred.numpy())\n",
    "            \n",
    "            # Update sequence: remove oldest, add new prediction\n",
    "            current_sequence = torch.cat([current_sequence[1:], pred.unsqueeze(0)])\n",
    "        \n",
    "        return np.array(predictions)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def reconstruct_images(self, test_sequences, num_samples=5):\n",
    "        \"\"\"Reconstruct images using the VAR model\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        reconstructions = []\n",
    "        original_images = []\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # Get test sequence and target\n",
    "            test_seq = test_sequences[i].unsqueeze(0)\n",
    "            target_img = test_sequences[i+1][-1]  # The actual next image\n",
    "            \n",
    "            # Predict next image\n",
    "            pred_img = self.model(test_seq).squeeze(0)\n",
    "            \n",
    "            reconstructions.append(pred_img.numpy())\n",
    "            original_images.append(target_img.numpy())\n",
    "        \n",
    "        return np.array(reconstructions), np.array(original_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization functions for MNIST\n",
    "def plot_mnist_training_curves(train_losses, test_losses):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(test_losses, label='Test Loss')\n",
    "    plt.title('MNIST VAR Model Training Progress')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.semilogy(train_losses, label='Training Loss (log)')\n",
    "    plt.semilogy(test_losses, label='Test Loss (log)')\n",
    "    plt.title('Training Progress (Log Scale)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE Loss (log)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('mnist_var_training_curves.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570637f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mnist_reconstructions(reconstructions, originals, num_samples=5):\n",
    "    \"\"\"Plot original MNIST images vs reconstructions\"\"\"\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original image\n",
    "        orig_img = originals[i].reshape(28, 28)\n",
    "        axes[0, i].imshow(orig_img, cmap='gray')\n",
    "        axes[0, i].set_title(f'Original {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Reconstructed image\n",
    "        recon_img = reconstructions[i].reshape(28, 28)\n",
    "        axes[1, i].imshow(recon_img, cmap='gray')\n",
    "        axes[1, i].set_title(f'Reconstructed {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('MNIST VAR Model: Original vs Reconstructed Images')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('mnist_var_reconstructions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c85451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sequence_generation(initial_sequence, generated_sequence, original_data, lag_order):\n",
    "    \"\"\"Plot the sequence generation process\"\"\"\n",
    "    num_steps = len(generated_sequence)\n",
    "    fig, axes = plt.subplots(2, num_steps + 1, figsize=(15, 6))\n",
    "    \n",
    "    # Plot initial sequence (lag_order images)\n",
    "    for i in range(lag_order):\n",
    "        img = initial_sequence[i].reshape(28, 28)\n",
    "        axes[0, i].imshow(img, cmap='gray')\n",
    "        axes[0, i].set_title(f'Initial {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "    \n",
    "    axes[0, lag_order].axis('off')\n",
    "    \n",
    "    # Plot generated sequence\n",
    "    for i in range(num_steps):\n",
    "        img = generated_sequence[i].reshape(28, 28)\n",
    "        axes[1, i].imshow(img, cmap='gray')\n",
    "        axes[1, i].set_title(f'Generated {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    axes[1, num_steps].axis('off')\n",
    "    \n",
    "    plt.suptitle('MNIST VAR Sequence Generation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('mnist_var_sequence_generation.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25de84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pixel_correlations(original_data, sample_size=1000):\n",
    "    \"\"\"Plot correlation between different pixel regions\"\"\"\n",
    "    # Use a subset of data\n",
    "    data_subset = original_data[:sample_size].reshape(sample_size, -1)\n",
    "    \n",
    "    # Calculate correlation matrix for a subset of pixels\n",
    "    pixel_indices = np.random.choice(data_subset.shape[1], 100, replace=False)\n",
    "    corr_matrix = np.corrcoef(data_subset[:, pixel_indices].T)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    im = plt.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.colorbar(im)\n",
    "    plt.title('Pixel Correlation Matrix (100 random pixels)')\n",
    "    plt.xlabel('Pixel Index')\n",
    "    plt.ylabel('Pixel Index')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('mnist_pixel_correlations.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "def main():\n",
    "    print(\"VAR Model for MNIST with Linear Layers\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Model parameters\n",
    "    input_dim = 28 * 28  # MNIST image size\n",
    "    lag_order = 5  # How many past images to use for prediction\n",
    "    hidden_dims = [1024, 512, 256]  # Linear layer dimensions\n",
    "    \n",
    "    # Initialize model and trainer\n",
    "    model = MNISTVARModel(input_dim=input_dim, lag_order=lag_order, hidden_dims=hidden_dims)\n",
    "    \n",
    "    trainer = MNISTVARTrainer(model, lr=0.001)\n",
    "    \n",
    "    print(f\"Model Architecture:\")\n",
    "    print(f\"- Input dimension: {input_dim} (28x28 MNIST images)\")\n",
    "    print(f\"- Lag order: {lag_order}\")\n",
    "    print(f\"- Hidden dimensions: {hidden_dims}\")\n",
    "    print(f\"- Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print()\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Training MNIST VAR model...\")\n",
    "    train_losses, test_losses, (X_train, y_train, X_test, y_test), original_data, labels = trainer.train(epochs=100)\n",
    "    \n",
    "    print(f\"\\nTraining completed!\")\n",
    "    print(f\"Final Training Loss: {train_losses[-1]:.6f}\")\n",
    "    print(f\"Final Test Loss: {test_losses[-1]:.6f}\")\n",
    "    \n",
    "    # Plot training results\n",
    "    plot_mnist_training_curves(train_losses, test_losses)\n",
    "    \n",
    "    # Plot pixel correlations\n",
    "    plot_pixel_correlations(original_data)\n",
    "    \n",
    "    # Generate reconstructions\n",
    "    print(\"\\nGenerating image reconstructions...\")\n",
    "    reconstructions, originals = trainer.reconstruct_images(X_test, num_samples=8)\n",
    "    plot_mnist_reconstructions(reconstructions, originals, num_samples=8)\n",
    "    \n",
    "    # Generate sequence\n",
    "    print(\"Generating image sequence...\")\n",
    "    initial_sequence = X_test[0]  # First test sequence\n",
    "    generated_sequence = trainer.predict_sequence(initial_sequence, steps=8)\n",
    "    plot_sequence_generation(initial_sequence, generated_sequence, original_data, lag_order)\n",
    "    \n",
    "    # Statistical analysis\n",
    "    print(f\"\\nStatistical Summary:\")\n",
    "    print(f\"Best training loss: {min(train_losses):.6f}\")\n",
    "    print(f\"Best test loss: {min(test_losses):.6f}\")\n",
    "    \n",
    "    # Calculate reconstruction quality\n",
    "    mse_reconstruction = np.mean((reconstructions - originals) ** 2)\n",
    "    print(f\"Average reconstruction MSE: {mse_reconstruction:.6f}\")\n",
    "    \n",
    "    # Show sample predictions vs actuals\n",
    "    print(f\"\\nSample Pixel-wise Comparison (first 10 pixels):\")\n",
    "    sample_pred = reconstructions[0][:10]\n",
    "    sample_actual = originals[0][:10]\n",
    "    \n",
    "    for i in range(10):\n",
    "        print(f\"Pixel {i}: Pred {sample_pred[i]:.3f}, Actual {sample_actual[i]:.3f}, Diff {abs(sample_pred[i]-sample_actual[i]):.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
